---
title: Fediverse Moderation
date: Last Modified
---

Moderation seems to be a very hot topic on the fediverse. Some people seem to expect every new instance to be vetted and manually approved by every other instance. Some people (like me) think thats a terrible idea. This post discusses what we will do, and what options people will have, for moderation on our work-in-progress fediverse project. 

The goal is obvious: Allow the maximum onboarding and ease of use for everyone while protecting as many people as possible. 

The first, and most obvious, partial solution is a shared blocklist. The problem with this is that it can be easily abuseable if one is used by everyone. The other problem is that people may just drop off the face of the fediverse if thier instance gets blocked. 

Well no problem with the seccond one, just add the permissions: 
- Can always message/contact me
- Can never message/contact me
- Follow instance prefrence

The first issue is harder to solve, but I believe it can be done. First of all, the person or group in charge should be **fully transparent** on what they are doing and why. They should also allow appeals and take full responseability for any false ratings. 

Of course, not everyone will want to implement that: so they of course don't need to.  Instances can chose to use a blocklist, whitelist, blacklist, greylist, or however they want to moderate. 

Another solution is a trust factor, which can help with the shared lists. We now intend to create a committe to maintain and moderate the lists. We likely will not have any one list, but instead rank every instance on a **trust factor** system. 

In short, you can allow instances over 4.00 unless othersise specified, ban below 2.00, and everything else is allowed at user discresion. This cuts down on work for the moderators as you can easily set your own thresholds. Users would also be able to use thier own block lists and modify thier scores. 

Scores will be reevaluated upon appeal to the council of course, and must be submitted to the cousil for evaluation. The council would rank it from 1 (non existent) to 6 (perfect with a very very small error margin) in various categories, and the average would be taken between them. 

The categories would be: 

- Moderation against transphobia
- Moderation against homophobia
- Moderation against ableism/discrimation against neurodivergent people
- Moderation against racism
- Moderation against spam
- Moderation against hate-speech
- Moderation against general toxicity
- General safety (basically a chance for them to add or doc points based on non-accounted for categories)

The scores will then be averaged and the instance will be given its trust factor. 

<!-- ![a](img.jpg) -->